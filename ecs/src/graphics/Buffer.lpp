$ require "common"

@@lpp.import "graphics/RendererInternal.lh"

@@lpp.import "graphics/Buffer.lh"
@@lpp.import "graphics/Geo.lh"
@@lpp.import "graphics/Renderer.lh"

#include "iro/Logger.h"

@defFileLogger(gfx.buffer, Info)

namespace gfx
{

/* ----------------------------------------------------------------------------
 */
b8 Buffer::init(
  Renderer& renderer,
  void* initial_data,
  u64 requested_size,
  Usage usage,
  MemoryProperty properties,
  MappingBehavior behavior,
  String name)
{
  RendererInternal& ri = *(RendererInternal*)renderer.internal;
  TRACE("initializing a buffer with ",requested_size," bytes\n");

  mapped_data = nullptr;

  if (index != 0)
    return ERROR("failed to initialize a buffer because the buffer"
      " is already initialized\n");

  if (ri.buffer_count >= ri.buffer_pool.MAX_COUNT)
    return ERROR("failed to initialize a buffer because the maximum"
      " number of buffers has been reached (",
      ri.buffer_pool.MAX_COUNT, ")\n");

  if (requested_size == 0)
    return ERROR("failed to initialize a buffer because the size is"
      " not positive\n");

  if (   (properties & MemoryProperty::LazilyAllocated)
      && (properties &
          ( MemoryProperty::HostVisible
          | MemoryProperty::HostCoherent)))
    return ERROR("MemoryProperty::LazilyAllocated is incompatible with"
      " MemoryProperty::HostVisible and MemoryProperty::HostCoherent\n");

  if (   (behavior == MappingBehavior::Never)
      && (properties &
          ( MemoryProperty::HostVisible
          | MemoryProperty::HostCoherent
          | MemoryProperty::HostCached)))
    return ERROR("MappingBehavior::Never is incompatible with"
      " MemoryProperty::HostVisible, MemoryProperty::HostCoherent,"
      " and MemoryProperty::HostCached\n");

  VkBufferUsageFlags vk_usage = 0;
  switch (usage)
  {
    case Usage::UniformBuffer:
      vk_usage = VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT;
      break;
    case Usage::StorageBuffer:
      vk_usage = VK_BUFFER_USAGE_STORAGE_BUFFER_BIT;
      break;
    case Usage::IndexBuffer:
      vk_usage = VK_BUFFER_USAGE_INDEX_BUFFER_BIT;
      break;
    case Usage::VertexBuffer:
      vk_usage = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT;
      break;
  }
  if (behavior == MappingBehavior::Never)
    vk_usage |= VK_BUFFER_USAGE_TRANSFER_DST_BIT;

  VkBufferCreateInfo create_info =
  {
    .sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO,
    .size = requested_size,
    .usage = vk_usage,
    .sharingMode = VK_SHARING_MODE_EXCLUSIVE,
  };

  VkBuffer buffer_handle;
  if (VK_SUCCESS != vkCreateBuffer(ri.device, &create_info,
    &ri.allocator, &buffer_handle))
    return ERROR("failed to create a vulkan buffer\n");
  auto delete_buffer_if_failure = deferWithCancel
  {
    vkDestroyBuffer(ri.device, buffer_handle, &ri.allocator);
  };

  VkMemoryRequirements memory_requirements;
  vkGetBufferMemoryRequirements(ri.device, buffer_handle,
    &memory_requirements);

  VkMemoryPropertyFlags vk_properties = 0;
  if (properties & MemoryProperty::DeviceLocal)
    vk_properties |= VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
  if (properties & MemoryProperty::HostVisible)
    vk_properties |= VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT;
  if (properties & MemoryProperty::HostCoherent)
    vk_properties |= VK_MEMORY_PROPERTY_HOST_COHERENT_BIT;
  if (properties & MemoryProperty::HostCached)
    vk_properties |= VK_MEMORY_PROPERTY_HOST_CACHED_BIT;
  if (properties & MemoryProperty::LazilyAllocated)
    vk_properties |= VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT;

  u32 memory_type = determineMemoryType(renderer, memory_requirements,
    vk_properties);

  RendererHeapAllocation* allocation = gfx::allocate(renderer,
    memory_type, memory_requirements);
  if (allocation == nullptr)
    return ERROR("failed to allocate memory for a vulkan buffer\n");
  auto deallocate_if_failure = deferWithCancel
  {
    gfx::deallocate(renderer, allocation);
  };

  if (VK_SUCCESS != vkBindBufferMemory(ri.device, buffer_handle,
    allocationMemory(renderer, allocation), allocation->aligned_offset))
    return ERROR("failed to bind memory to a vulkan buffer\n");

  if (behavior == MappingBehavior::Never)
  {
    if (initial_data == nullptr)
    {
      WARN("Allocated a buffer with no initial data and"
        " MappingBehavior::Never specified, so the buffer will not be able to"
        " be mapped and written to. This is mainly usefuly for intermediate"
        " compute shader memory, but compute shaders are not setup yet.\n");
    }
    else
    {
      VkBufferCreateInfo staging_buffer_create_info =
      {
        .sType = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO,
        .size = memory_requirements.size,
        .usage = VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
        .sharingMode = VK_SHARING_MODE_EXCLUSIVE,
      };

      VkBuffer staging_buffer_handle;
      if (VK_SUCCESS != vkCreateBuffer(ri.device,
        &staging_buffer_create_info, &ri.allocator, &staging_buffer_handle))
        return ERROR("failed to create a vulkan staging buffer to upload"
          " initial buffer data\n");
      defer
      {
        vkDestroyBuffer(ri.device, staging_buffer_handle, &ri.allocator);
      };

      VkMemoryRequirements staging_memory_requirements;
      vkGetBufferMemoryRequirements(ri.device,
        (VkBuffer)staging_buffer_handle, &staging_memory_requirements);

      VkMemoryPropertyFlags vk_staging_properties =
          VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT
        | VK_MEMORY_PROPERTY_HOST_COHERENT_BIT;

      u32 staging_memory_type = determineMemoryType(renderer,
        staging_memory_requirements, vk_staging_properties);

      RendererHeapAllocation* staging_allocation =
        gfx::allocate(renderer, staging_memory_type,
          staging_memory_requirements);
      if (staging_allocation == nullptr)
        return ERROR("failed to allocate memory for a staging buffer when"
          " uploading initial buffer data\n");
      defer { gfx::deallocate(renderer, staging_allocation); };

      VkDeviceMemory staging_buffer_memory =
        allocationMemory(renderer, staging_allocation);

      if (VK_SUCCESS != vkBindBufferMemory(ri.device, staging_buffer_handle,
        staging_buffer_memory, staging_allocation->aligned_offset))
        return ERROR("failed to bind memory to a vulkan staging buffer when"
          " trying to upload initial buffer data\n");

      void* staging_memory_data;
      if (VK_SUCCESS != vkMapMemory(ri.device, staging_buffer_memory,
        staging_allocation->aligned_offset, memory_requirements.size, 0,
        &staging_memory_data))
        return ERROR("failed to map memory for a vulkan staging buffer when"
          " trying to upload initial buffer data\n");

      mem::copy(staging_memory_data, initial_data, requested_size);

      vkUnmapMemory(ri.device, staging_buffer_memory);

      VkCommandBuffer single_use_command_buffer;
      if (!beginSingleUseCommandBuffer(renderer, &single_use_command_buffer))
        return false;

      VkBufferCopy copy_region =
      {
        .size = requested_size,
      };

      vkCmdCopyBuffer(single_use_command_buffer, staging_buffer_handle,
        buffer_handle, 1, &copy_region);

      if(!endSingleUseCommandBuffer(renderer, single_use_command_buffer))
        return false;
    }
  }
  else if (behavior == MappingBehavior::Occasional)
  {
    if (initial_data != nullptr)
    {
      RendererHeap& heap = ri.heaps[allocation->memory_type];
      RendererHeapBlock& block = heap.blocks[allocation->block_index];

      if (VK_SUCCESS != vkMapMemory(ri.device, block.memory,
        allocation->aligned_offset, memory_requirements.size, 0, &mapped_data))
        return ERROR("failed to map memory when trying to upload initial"
          " vulkan buffer data\n");
      defer { vkUnmapMemory(ri.device, block.memory); };

      mem::copy(mapped_data, initial_data, requested_size);

      VkMappedMemoryRange range =
      {
        .sType = VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE,
        .memory = block.memory,
        .offset = allocation->aligned_offset,
        .size = VK_WHOLE_SIZE,
      };

      if (VK_SUCCESS != vkFlushMappedMemoryRanges(ri.device, 1, &range))
        return ERROR("failed to flush mapped memory when trying to upload"
          " initial vulkan buffer data\n");
    }
  }
  else
  {
    assert(behavior == MappingBehavior::Persistent);

    RendererHeap& heap = ri.heaps[allocation->memory_type];
    RendererHeapBlock& block = heap.blocks[allocation->block_index];

    if (VK_SUCCESS != vkMapMemory(ri.device, block.memory,
      allocation->aligned_offset, memory_requirements.size, 0, &block.mapped_data))
      return ERROR("failed to map memory when trying to upload initial"
        " vulkan buffer data\n");
    mapped_data = block.mapped_data;

    if (initial_data != nullptr)
    {
      mem::copy(mapped_data, initial_data, requested_size);

      VkMappedMemoryRange range =
      {
        .sType = VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE,
        .memory = block.memory,
        .offset = allocation->aligned_offset,
        .size = VK_WHOLE_SIZE,
      };

      if (VK_SUCCESS != vkFlushMappedMemoryRanges(ri.device, 1, &range))
      {
        vkUnmapMemory(ri.device, block.memory);
        return ERROR("failed to flush mapped memory when trying to upload"
          " initial vulkan buffer data\n");
      }
    }
  }

  VkDescriptorSet descriptor_set = VK_NULL_HANDLE;
  if (usage == Usage::UniformBuffer || usage == Usage::StorageBuffer)
  {
    VkDescriptorSetAllocateInfo alloc_info =
    {
      .sType = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO,
      .descriptorPool = ri.descriptor_pool,
      .descriptorSetCount = 1,
      .pSetLayouts = (usage == Usage::UniformBuffer)
        ? &ri.default_uniform_buffer_descriptor_set_layout
        : &ri.default_storage_buffer_descriptor_set_layout,
    };

    if (VK_SUCCESS != vkAllocateDescriptorSets(ri.device, &alloc_info,
      &descriptor_set))
      return ERROR("failed to allocate a descriptor set for a vulkan buffer\n");

    VkDescriptorType descriptor_type;
    if (usage == Usage::UniformBuffer)
      descriptor_type = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER;
    else
      descriptor_type = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER;

    VkDescriptorBufferInfo descriptor_info =
    {
      .buffer = buffer_handle,
      .offset = 0,
      .range = requested_size,
    };

    VkWriteDescriptorSet descriptor_set_write =
    {
      .sType = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
      .dstSet = descriptor_set,
      .dstBinding = 0,
      .dstArrayElement = 0,
      .descriptorCount = 1,
      .descriptorType = descriptor_type,
      .pBufferInfo = &descriptor_info,
    };

    vkUpdateDescriptorSets(ri.device, 1, &descriptor_set_write, 0, nullptr);
  }

  RendererBuffer* buffer = ri.buffer_pool.add();
  buffer->buffer = buffer_handle;
  buffer->allocation = allocation;
  buffer->descriptor_set = descriptor_set;
  index = ri.buffer_pool.index_of(buffer);
  ri.buffer_count++;

  debugSetObjectName(renderer, VK_OBJECT_TYPE_BUFFER, buffer_handle,
    "<", name, " buffer>");
  debugSetObjectName(renderer, VK_OBJECT_TYPE_DESCRIPTOR_SET, descriptor_set,
    "<", name, " descriptor>");

  delete_buffer_if_failure.cancel();
  deallocate_if_failure.cancel();
  return true;
}

/* ----------------------------------------------------------------------------
 */
b8 Buffer::deinit(Renderer& renderer)
{
  RendererInternal& ri = *(RendererInternal*)renderer.internal;
  TRACE("deinitializing the buffer at index ",index,"\n");

  if (index == 0)
    return true;

  RendererBuffer* buffer = ri.buffer_pool.at_index(index);
  if (buffer == nullptr)
    return ERROR("attempted to destroy a buffer at index ", index,
      " which is out of bounds\n");

  if (buffer->buffer == VK_NULL_HANDLE)
    return ERROR("attempted to destroy an uninitialized buffer\n");

  if (mapped_data != nullptr)
  {
    RendererHeap& heap = ri.heaps[buffer->allocation->memory_type];
    RendererHeapBlock& block = heap.blocks[buffer->allocation->block_index];

    block.mapped_count--;
    if (block.mapped_count == 0)
    {
      vkUnmapMemory(ri.device, block.memory);
      block.mapped_data = nullptr;
    }
  }

  vkDestroyBuffer(ri.device, buffer->buffer, &ri.allocator);
  gfx::deallocate(renderer, buffer->allocation);

  mapped_data = nullptr;
  buffer->buffer = VK_NULL_HANDLE;
  buffer->allocation = nullptr;
  buffer->descriptor_set = VK_NULL_HANDLE;

  index = 0;
  ri.buffer_pool.remove(buffer);
  ri.buffer_count--;

  return true;
}

/* ----------------------------------------------------------------------------
 */
b8 Buffer::map(Renderer& renderer)
{
  RendererInternal& ri = *(RendererInternal*)renderer.internal;
  TRACE("mapping the buffer at index ", index, "\n");

  if (index == 0)
    return ERROR("attempted to map an uninitialized buffer\n");

  RendererBuffer* buffer = ri.buffer_pool.at_index(index);
  if (buffer == nullptr)
    return ERROR("attempted to map the buffer at index ", index,
      " which is out of bounds\n");

  if (buffer->buffer == VK_NULL_HANDLE)
    return ERROR("attempted to map an uninitialized buffer\n");
  assert(buffer->allocation != nullptr);

  if (mapped_data != nullptr)
    return ERROR("attempted to map the already mapped buffer at index ",
      index, "\n");

  RendererHeap& heap = ri.heaps[buffer->allocation->memory_type];
  RendererHeapBlock& block = heap.blocks[buffer->allocation->block_index];

  if (block.mapped_data == nullptr)
  {
    if (VK_SUCCESS != vkMapMemory(ri.device, block.memory, 0, VK_WHOLE_SIZE, 0,
      &block.mapped_data))
      return ERROR("failed to map the buffer at index ", index, "\n");
  }

  mapped_data = (u8*)block.mapped_data + buffer->allocation->aligned_offset;
  block.mapped_count++;
  return true;
}

/* ----------------------------------------------------------------------------
 */
b8 Buffer::flush(Renderer& renderer, u64 offset, u64 size)
{
  RendererInternal& ri = *(RendererInternal*)renderer.internal;

  if (size == FLUSH_WHOLE_BUFFER)
    TRACE("flushing the whole buffer at index ", index, "\n");
  else
    TRACE("flushing ", size, " bytes of the buffer at index ", index, "\n");

  if (index == 0)
    return ERROR("attempted to flush an uninitialized buffer\n");

  RendererBuffer* buffer = ri.buffer_pool.at_index(index);
  if (buffer == nullptr)
    return ERROR("attempted to flush the buffer at index ", index,
      " which is out of bounds\n");

  if (buffer->buffer == VK_NULL_HANDLE)
    return ERROR("attempted to flush an uninitialized buffer\n");
  assert(buffer->allocation != nullptr);

  if (mapped_data == nullptr)
    return ERROR("attempted to flush an unmapped buffer\n");

  RendererHeap& heap = ri.heaps[buffer->allocation->memory_type];
  RendererHeapBlock& block = heap.blocks[buffer->allocation->block_index];

  VkDeviceSize aligned_offset =
    alignDown(buffer->allocation->aligned_offset + offset, heap.alignment);
  VkDeviceSize flush_size = (size == FLUSH_WHOLE_BUFFER)
    ? VK_WHOLE_SIZE : alignUp(size, heap.alignment);

  VkMappedMemoryRange range =
  {
    .sType = VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE,
    .memory = block.memory,
    .offset = aligned_offset,
    .size = flush_size,
  };

  if (VK_SUCCESS != vkFlushMappedMemoryRanges(ri.device, 1, &range))
    return ERROR("failed to flush ", flush_size, " bytes of the buffer"
      " at index ", index, "\n");

  return true;
}

/* ----------------------------------------------------------------------------
 */
b8 Buffer::copy_and_flush(Renderer& renderer, void* data, u64 size)
{
  RendererInternal& ri = *(RendererInternal*)renderer.internal;
  TRACE("copying and flushing the buffer at index ", index, "\n");
  
  if (index == 0)
    return ERROR("attempted to copy and flush an uninitialized buffer\n");

  RendererBuffer* buffer = ri.buffer_pool.at_index(index);
  if (buffer == nullptr)
    return ERROR("attempted to copy and flush the buffer at index ", index,
      " which is out of bounds\n");

  if (buffer->buffer == VK_NULL_HANDLE)
    return ERROR("attempted to copy and flush an uninitialized buffer\n");
  assert(buffer->allocation != nullptr);

  if (mapped_data == nullptr)
    return ERROR("attempted to copy and flush an unmapped buffer\n");

  RendererHeap& heap = ri.heaps[buffer->allocation->memory_type];
  RendererHeapBlock& block = heap.blocks[buffer->allocation->block_index];

  mem::copy(mapped_data, data, size);

  VkDeviceSize flush_size = alignUp(size, heap.alignment);
  VkMappedMemoryRange range =
  {
    .sType = VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE,
    .memory = block.memory,
    .offset = buffer->allocation->aligned_offset,
    .size = flush_size,
  };

  if (VK_SUCCESS != vkFlushMappedMemoryRanges(ri.device, 1, &range))
    return ERROR("failed to flush ", flush_size, " bytes of the buffer"
      " at index ", index, "\n");

  return true;
}

/* ----------------------------------------------------------------------------
 */
b8 Buffer::unmap(Renderer& renderer)
{
  RendererInternal& ri = *(RendererInternal*)renderer.internal;
  TRACE("unmapping the buffer at index ", index, "\n");

  if (mapped_data == nullptr)
    return true;

  if (index == 0)
    return ERROR("attempted to unmap an uninitialized buffer\n");

  RendererBuffer* buffer = ri.buffer_pool.at_index(index);
  if (buffer == nullptr)
    return ERROR("attempted to unmap the buffer at index ", index,
      " which is out of bounds\n");

  if (buffer->buffer == VK_NULL_HANDLE)
    return ERROR("attempted to unmap an uninitialized buffer\n");
  assert(buffer->allocation != nullptr);

  RendererHeap& heap = ri.heaps[buffer->allocation->memory_type];
  RendererHeapBlock& block = heap.blocks[buffer->allocation->block_index];
  
  block.mapped_count--;
  if (block.mapped_count == 0)
  {
    vkUnmapMemory(ri.device, block.memory);
    block.mapped_data = nullptr;
  }

  mapped_data = nullptr;
  return true;
}

}
